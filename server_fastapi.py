import io
import gc
import re
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image, ImageEnhance, ImageFilter, ImageOps
import pytesseract
import logging
import cv2
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="OCR ID Parser - Enhanced Arabic OCR")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def optimize_memory():
    """ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
    gc.collect()

def enhance_image_for_arabic_text(image):
    """ØªØ­Ø³ÙŠÙ† Ù…ØªÙ‚Ø¯Ù… Ù„Ù„ØµÙˆØ±Ø© Ù…Ø®ØµØµ Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª"""
    
    # ØªØ­ÙˆÙŠÙ„ PIL Ø¥Ù„Ù‰ OpenCV
    img_array = np.array(image)
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© Ù…Ù„ÙˆÙ†Ø©ØŒ ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
    if len(img_array.shape) == 3:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray = img_array
    
    # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø¯Ù‚Ø© Ù„ØªØ­Ø³ÙŠÙ† Ø¯Ù‚Ø© OCR
    scale_factor = 2
    new_width = gray.shape[1] * scale_factor
    new_height = gray.shape[0] * scale_factor
    resized = cv2.resize(gray, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
    
    # ØªØ·Ø¨ÙŠÙ‚ ØªØµÙÙŠØ© Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ø¯Ø©
    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
    sharpened = cv2.filter2D(resized, -1, kernel)
    
    # ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    contrast_enhanced = clahe.apply(sharpened)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¸Ù„Ø§Ù„ Ø¥Ù„Ù‰ Ø£Ø¨ÙŠØ¶ Ù†Ù‚ÙŠ ÙˆØ§Ù„Ø®Ù„ÙÙŠØ© Ø¥Ù„Ù‰ Ø³ÙˆØ¯Ø§Ø¡
    _, binary = cv2.threshold(contrast_enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # ØªØ­ÙˆÙŠÙ„ kembali ke PIL Image
    result_image = Image.fromarray(binary)
    
    return result_image

def preprocess_multiple_techniques(image):
    """ØªØ¬Ø±Ø¨Ø© ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©"""
    
    techniques = []
    
    # Ø§Ù„ØªÙ‚Ù†ÙŠØ© 1: ØªØ­Ø³ÙŠÙ† Ø£Ø³Ø§Ø³ÙŠ
    gray = image.convert('L')
    enhancer = ImageEnhance.Contrast(gray)
    basic_enhanced = enhancer.enhance(2.0)
    techniques.append(basic_enhanced)
    
    # Ø§Ù„ØªÙ‚Ù†ÙŠØ© 2: ØªØ­Ø³ÙŠÙ† Ù…ØªÙ‚Ø¯Ù…
    advanced_enhanced = enhance_image_for_arabic_text(image)
    techniques.append(advanced_enhanced)
    
    # Ø§Ù„ØªÙ‚Ù†ÙŠØ© 3: ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
    denoised = gray.filter(ImageFilter.MedianFilter(size=3))
    enhancer_denoise = ImageEnhance.Contrast(denoised)
    denoise_enhanced = enhancer_denoise.enhance(2.5)
    techniques.append(denoise_enhanced)
    
    return techniques

def clean_arabic_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
    if not text:
        return ""
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨ ÙÙŠÙ‡Ø§ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù…
    arabic_pattern = r'[^\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF0-9\s\-\.\/]'
    cleaned = re.sub(arabic_pattern, '', text)
    
    # ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª
    cleaned = re.sub(r'\s+', ' ', cleaned)
    
    # ØªØµØ­ÙŠØ­ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    number_corrections = {
        'Ù ': 'Ù ', 'Û°': 'Ù ',  # ØµÙØ± Ø¹Ø±Ø¨ÙŠ
        'Ù¡': 'Ù¡', 'Û±': 'Ù¡',  # ÙˆØ§Ø­Ø¯
        'Ù¢': 'Ù¢', 'Û²': 'Ù¢',  # Ø§Ø«Ù†Ø§Ù†
        'Ù£': 'Ù£', 'Û³': 'Ù£',  # Ø«Ù„Ø§Ø«Ø©
        'Ù¤': 'Ù¤', 'Û´': 'Ù¤',  # Ø£Ø±Ø¨Ø¹Ø©
        'Ù¥': 'Ù¥', 'Ûµ': 'Ù¥',  # Ø®Ù…Ø³Ø©
        'Ù¦': 'Ù¦', 'Û¶': 'Ù¦',  # Ø³ØªØ©
        'Ù§': 'Ù§', 'Û·': 'Ù§',  # Ø³Ø¨Ø¹Ø©
        'Ù¨': 'Ù¨', 'Û¸': 'Ù¨',  # Ø«Ù…Ø§Ù†ÙŠØ©
        'Ù©': 'Ù©', 'Û¹': 'Ù©',  # ØªØ³Ø¹Ø©
    }
    
    for wrong, correct in number_corrections.items():
        cleaned = cleaned.replace(wrong, correct)
    
    # ÙØµÙ„ Ø§Ù„Ø£Ø³Ø·Ø± Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­
    lines = [line.strip() for line in cleaned.split('\n') if line.strip()]
    
    # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù‡ÙŠÙƒÙ„
    final_text = "\n".join(lines)
    
    return final_text.strip()

@app.get("/")
async def home():
    return {"message": "ğŸš€ Enhanced Arabic OCR API Running!"}

@app.post("/parse-image")
async def parse_image(file: UploadFile = File(...)):
    try:
        optimize_memory()
        
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØµÙˆØ±Ø©")
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
        image_bytes = await file.read()
        image = Image.open(io.BytesIO(image_bytes))
        
        logger.info(f"ğŸ“· Ù…Ø¹Ø§Ù„Ø¬Ø© ØµÙˆØ±Ø©: {image.size} - {image.mode}")
        
        # ØªØ¬Ø±Ø¨Ø© ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©
        processed_images = preprocess_multiple_techniques(image)
        
        all_results = []
        
        for i, processed_img in enumerate(processed_images):
            logger.info(f"ğŸ” ØªØ¬Ø±Ø¨Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ© {i+1}")
            
            # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Tesseract Ù…Ø®ØªÙ„ÙØ© Ù„ÙƒÙ„ ØªÙ‚Ù†ÙŠØ©
            configs = [
                '--oem 3 --psm 6 -c tessedit_char_whitelist=Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©0123456789Ø§Ø¨Ø¬Ø¯Ù‡ÙˆØ²Ø­Ø·ÙŠÙƒÙ„Ù…Ù†Ø³Ø¹ÙØµÙ‚Ø±Ø´ØªØ«Ø®Ø°Ø¶Ø¸ØºØ¡Ø¢Ø£Ø¤Ø¥Ø¦Ø©Ù‰',
                '--oem 3 --psm 4',  # PSM 4 Ù„Ù„ÙƒØªÙ„Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„Ù†Øµ
                '--oem 3 --psm 11',  # PSM 11 Ù„Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù„Øµ
            ]
            
            for config in configs:
                try:
                    text = pytesseract.image_to_string(
                        processed_img,
                        lang='ara+eng',
                        config=config
                    )
                    
                    cleaned_text = clean_arabic_text(text)
                    if cleaned_text and len(cleaned_text) > 10:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù‚ØµÙŠØ±Ø©
                        all_results.append({
                            'technique': f'tech_{i+1}_config_{configs.index(config)+1}',
                            'text': cleaned_text,
                            'length': len(cleaned_text)
                        })
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªÙ‚Ù†ÙŠØ© {i+1}: {e}")
                    continue
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø© (Ø§Ù„Ø£Ø·ÙˆÙ„ Ø¹Ø§Ø¯Ø©Ù‹)
        if all_results:
            best_result = max(all_results, key=lambda x: x['length'])
            final_text = best_result['text']
            logger.info(f"âœ… Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©: {best_result['technique']} - Ø·ÙˆÙ„: {best_result['length']}")
        else:
            final_text = ""
            logger.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†Øµ")
        
        # ØªØ­Ø±ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        del image, processed_images, image_bytes
        optimize_memory()
        
        return {
            "success": True,
            "text": final_text,
            "backend": "Tesseract-Arabic-Enhanced",
            "techniques_tried": len(processed_images),
            "results_found": len(all_results)
        }
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£: {e}")
        optimize_memory()
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")

@app.post("/parse-image-detailed")
async def parse_image_detailed(file: UploadFile = File(...)):
    """Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªØ§Ø¦Ø¬ Ù…ÙØµÙ„Ø© Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª"""
    try:
        optimize_memory()
        
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† ØµÙˆØ±Ø©")
        
        image_bytes = await file.read()
        image = Image.open(io.BytesIO(image_bytes))
        
        processed_images = preprocess_multiple_techniques(image)
        
        detailed_results = []
        
        for i, processed_img in enumerate(processed_images):
            configs = [
                ('psm6', '--oem 3 --psm 6'),
                ('psm4', '--oem 3 --psm 4'),
                ('psm11', '--oem 3 --psm 11'),
            ]
            
            for config_name, config in configs:
                try:
                    text = pytesseract.image_to_string(
                        processed_img,
                        lang='ara+eng',
                        config=config
                    )
                    
                    cleaned_text = clean_arabic_text(text)
                    
                    if cleaned_text and len(cleaned_text) > 5:
                        detailed_results.append({
                            'technique': f'tech_{i+1}',
                            'config': config_name,
                            'text': cleaned_text,
                            'length': len(cleaned_text)
                        })
                        
                except Exception as e:
                    continue
        
        # ØªØ­Ø±ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        del image, processed_images, image_bytes
        optimize_memory()
        
        return {
            "success": True,
            "all_results": detailed_results,
            "best_result": max(detailed_results, key=lambda x: x['length']) if detailed_results else None
        }
        
    except Exception as e:
        optimize_memory()
        raise HTTPException(status_code=500, detail=f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©: {str(e)}")
