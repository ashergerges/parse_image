import io
import os
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image
import pytesseract
import numpy as np
import logging

# ==========================
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ±ÙØ±
# ==========================
app = FastAPI(title="OCR ID Parser - Tesseract")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Ø£Ùˆ Ø¶Ø¹ Ù†Ø·Ø§Ù‚Ùƒ ÙÙ‚Ø·
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("server_fastapi")

# ==========================
# Ù†Ù‚Ø·Ø© Ø§Ù„ÙØ­Øµ
# ==========================
@app.get("/")
async def home():
    return {"message": "ğŸš€ OCR API Running with Tesseract!"}

# ==========================
# Ù†Ù‚Ø·Ø© Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§
# ==========================
@app.post("/parse-image")
async def parse_image(file: UploadFile = File(...)):
    try:
        logger.info("ğŸ“¥ Received image: %s", file.filename)
        image_bytes = await file.read()
        image = Image.open(io.BytesIO(image_bytes))

        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ numpy ÙˆØªØ­Ø³ÙŠÙ†Ù‡Ø§ Ù‚Ø¨Ù„ OCR
        img = np.array(image.convert("L"))  # ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
        text = pytesseract.image_to_string(img, lang="ara+eng")

        logger.info("âœ… OCR Done. Extracted text length: %d", len(text))
        return {"text": text.strip()}

    except Exception as e:
        logger.exception("âŒ Error during OCR:")
        raise HTTPException(status_code=500, detail=str(e))
