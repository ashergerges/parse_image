import io
import numpy as np
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from PIL import Image, ImageOps
import pytesseract
import logging

app = FastAPI(title="OCR Arabic ID Reader - Tesseract")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("server_fastapi")

@app.get("/")
async def root():
    return {"message": "ğŸš€ Arabic OCR API Running!"}

@app.post("/parse_image")
async def parse_image(file: UploadFile = File(...)):
    try:
        logger.info(f"ğŸ“¥ Received image: {file.filename}")
        image_bytes = await file.read()

        # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

        # ØªØ­ÙˆÙŠÙ„ Ù„ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ + Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØ¶ÙˆØ­
        gray = ImageOps.grayscale(image)
        gray = ImageOps.autocontrast(gray)

        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø¹Ø¨Ø± threshold Ø¨Ø³ÙŠØ·
        gray_np = np.array(gray)
        gray_np = np.where(gray_np > 160, 255, 0).astype(np.uint8)
        gray = Image.fromarray(gray_np)

        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·
        text = pytesseract.image_to_string(gray, lang="ara")

        text_clean = text.strip()
        logger.info(f"âœ… OCR Done. Extracted text length: {len(text_clean)}")

        return {"text": text_clean}

    except Exception as e:
        logger.exception("âŒ Error during OCR:")
        raise HTTPException(status_code=500, detail=str(e))
